# 计算机基础

最后编辑于23-9-3

本文会涉及计算机的组成，以及一些关于二进制的知识

## 二进制

**编写代码不需要你会二进制，不需要你直接写二进制，但是这一部分仍然很有必要**

### 进制

想必你一定学过数学，知道数字，比如说

* 自然数 $123456$
* 小数   $114.514$
* 负数   $-191810$



我们学的数字遵循**逢十进一**，什么意思呢

$9 + 1 = 10$，这就是**进位**，9是一个一位数，1也是，它们相加的结果是一个个位为0的两位数

如果只看个位，$9 + 1$ 得到了 $0$，最小的个位数 ~~不涉及负数~~

那么比9加1实际上的结果，表现在十位上，也就是$10$中的$1$

这便是**逢十进一**的**十进制数**

那么，如果一个数字逢n进一，就称之为n进制数

计算机内部使用的是二进制数字，遵循逢二进一

也就是说，二进制加法是这样的：$1 + 1 = 10$

注意这里的$1$不是十进制的$1$，$10$也不是十进制的$10$

二进制10 转换为 十进制其实就是2

通过给数字添加下标来分辨进制:

$110110_2$ 是二进制数，而$54$是十进制数字

### *进制转换

实际上数字可以这样拆分，比如对于一个十进制数字6574

$6574 = 6 * 10 ^ 3 + 5 * 10 ^ 2 + 7 * 10 ^ 1 + 4 * 10 ^ 0 = 6574$

~~好像什么都没发生？~~

那么对于$110110_2$，可以这样拆分

*为了方便观看我加上了括号*

$110110_2 = (1 * 2 ^ 5) + (1 * 2 ^ 4) + (0 * 2 ^ 3) + (1 * 2 ^ 2) + (1 * 2 ^ 1) + (0 * 2 ^ 0) = 32 + 16 + 4 + 2 = 54$

也就是说，$110110_2$就表示$54$，观察规律，这就是二进制转十进制的方法

那么同样的，将一个十进制数转换为一系列 一个数乘以2的一个次方式子 的和，就可以转换得到二进制

比如说$54 = (1 * 2 ^ 5) + (1 * 2 ^ 4) + (0 * 2 ^ 3) + (1 * 2 ^ 2) + (1 * 2 ^ 1) + (0 * 2 ^ 0) = 110110_2$

那么，这个转换是怎么进行的呢？一眼看不出来啊

其实很简单


*后面的 ....... 表示的是余数*

$27 / = 27 ...... 0$

$27 / 2 = 13 ...... 1$

$13 / 2 = 6  ...... 1$

$6  / 2 = 3  ...... 0$

$3  / 2 = 1  ...... 1$

$1  / 2 = 0  ...... 1$

那么从上到下查看余数，就是110110

其中原理自行体会，~~这个转换的方法只是了解一下而已，不是必须的，你看这一部分叫 *进制转换~~

## 数据类型

计算机内部的数字都是单纯的二进制数字，甚至没有符号，更没有小数点。毕竟成天面对一堆数字是不可能的，那不是人那是神仙。单纯的使用正整数，怎么表示各种东西呢

其实只需要**赋予数字意义**就可以

比如说，给数字加上单位，数字就有了”实际意义“，1只是1，而1m就可以表示一个现实中的长度

那么一样，给二进制数字加上”单位”。就可用二进制数字来表示各种东西。不过不同的是，这个“单位”甚至会改变其运算规则

这个“单位”就叫做**数据类型**

### 无符号整数类型

这个类型不改变任何东西，因为单纯的二进制就是**无符号整数类型**，它的运算也是正常的二进制运算

### 有符号整数类型

对于一个数字$100000001_2$，直接进行转换，它表示十进制的128

但是如果把二进制数字最高的一位，当成正负号，$1$表示负数，$0$表示正数，二进制数字就可以被用来表示负数了。那么

$100000001_2$就表示 $-126$。你可能对此感到困惑，怎么看都不像啊

但是就像前面说的，这个“单位”甚至会改变运算规则，它表示-126也是有原因的：

如果用$01111110_2$也就是$126$加上$-126$可以得到什么呢？

~~这个的Latex我不会写~~

```
  10000001
+ 01111110
-----------
  11111111
```

看起来还是很奇怪，但是不要着急，再给它加上1，也就是00000001你就知道一切是多么巧妙

```
  11111111
+ 00000001
------------
 100000001
```

如果忽略第九位的1，结果就是1：$-126 + 126 + 1 = 1$，很合理吧？

毕竟计算机的数字必须有个长度(工程上不允许~~但是逻辑上的实现是另一回事~~)，一个八位数字的第九位会被忽略，最后的结果不会是$100000001$，而是就是$00000001$。这个运算的过程，和结果，实际上是完全合理的

这个类型就叫做`有符号整数类型(integer)`，而这套机制叫做`补码`

其实你仔细看，这套机制**并没有**改变数字的运算规则，有符号整数类型的运算规则和无符号整数类型一模一样，这仅仅是从另一个角度去看待二进制数字

### 浮点数

目前为止，你已经知道了如何用二进制表示一个整数

那么，怎么用二进制表示一个小数呢？

如果你了解一些无穷级数的知识，你一定知道这个

<center>

$\sum_{n=1}^{\infty}2^{-n}=1$

</center>


那么，如果二进制的第n位不再是2^(n-1)而是2^(1-n)，就可以使用二进制来表示小数了

比如1就可以表示 1,而11表示1.5,111就可以表示1.75

*提示：$a^{-b}=\frac{1}{a^b}$*


$1_2   = 1 * 2 ^ 0 = 1$

$11_2  = 1 * 2 ^ {-1} + 1 * 2 ^ 0 = 1.5$

$111_2 = 1 * 2 ^ {-2} + 1 * 2 ^ {-1} + 1 * 2 ^ 0 = 1.75$

$101_2 = 1 * 2 ^ {-2} + 0 * 2 ^ {-1} + 1 * 2 ^ 0 = 1.25$

$100_2 = 1 * 2 ^ {-2} + 0 * 2 ^ {-1} + 0 * 2 ^ 0 = 0.25$

$111111...._2 = 1 + 1/2 + 1/4 + 1/16 + ... = 2$

但是想必你已经发现了一些问题：

1. 这样只能表示$[1,2)$的数字（为什么是半开半闭区间：计算机不会有无限位用来放差的那$2^{-n}$，距离2永远差那么一点点），然而实际上需要表示一个很大的数字

2. 别说无限位，就算用很大的位数也是不合实际的，这样就会有一点点误差（$0.1 + 0.2 \ne 0.3$很大可能是真命题，因为差了那么一点点）

3. 对于无理数[~~超纲了~~](../intro.md#对读者的要求)我只能说，**无能为力**，$\pi，e$这样的都只能取一个近似的浮点数

对于第二个问题，只能说：这是设计缺陷

但是对于第一个问题，结合一下小学知识：科学计数法，可以很好地解决

*对于一个数字$n$,可以使用科学计数法表示为$n = a * p^b$ ~~原话是什么我忘了~~*

比如说$123456 = 1.23456 * 10^5$

那么分别用两个二进制数表示其中的$a$和$b$，就可以表示相当多，和绝对值相当大的数字

那么，糅杂在一起，就构成了浮点数类型

一个32位的浮点数，其中的1位是**符号位**（表示正负），10位是**指数**（也就是b的部分，底也就是p等于2），11位是**尾数**（也就是a的部分）

~~这个具体多长你不用记，几乎用不上，仅仅了解下就可以~~

为什么要这样规定呢？如果没有规定，底数（p）是多少？多长是**尾数**？多长是**指数**？有没有**符号位**？都会是一个问题，甚至会出现不同的CPU的设计不同，导致运算速度，精度，可以表示的数字的范围不一样，这会是很麻烦的事

### 字符类型

~~其实很简单，一个数字对应一个字，就这么简单粗暴~~

字符是没规律的，没法用一个数字计算得到一个字符

那么要表示一个字符，就只能用类似”密码“的方法

用数字的一种唯一的排列组合，来对应一个文字

字符到数字叫做编码，数字到字符叫做解码

所以我就简单介绍下两种字符集（对应的标准）

而字符集和实现叫做字符编码（了解一下就可以了）

#### ascii

*美国信息交换用标准代码（全写为 American Standard Code for Information Interchange，使用不同程序的计算机可互相传送数据的一种标准码）*

ascii使用一个7位的二进制数字来表示一个字母，符号，或者别的，它占用的空间很小，每个ascii字符也用相同的空间，但是代价是可以表示的东西非常有限（常用中文都有几千个呢）

它存在的意义？它够简单，而且是一个标准，后来的高级的编码也都支持它

#### Unicode

当今世界上最流行的字符集

它可以表示相当多的字符，毕竟你看到的这个页面用的就是Unicode

Unicode可以表示八国文字，八国符号，😊emoji等等很多

为了节省空间，Unicode字符集有三个字符编码，分别是UTF-8，UTF-16，UTF-32

后面的数字表示的是这个字符使用空间的大小（二进制位数）

UTF32编码可以用一个32位的数字表示全部Unicode字符，而另两种则是看具体字符使用不一样大的空间来表示

#### 扩展阅读

不同操作系统内部使用的是不同的字符编码，这很恶心，但是rust内部的str和String类型使用的是UTF-8，char使用的是UTF-32，OsString使用的是操作系统的字符编码，rust提供它们之间的转换，这使得你在移植Rust程序时不需要考虑这方面的问题

